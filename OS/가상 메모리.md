# 가상 메모리

가상 메모리란 프로세스의 크기가 메인 메모리 공간 보다 큰 경우를 해결하기 위해 사용하는 방법으로 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능한 방법 이다. 가상메모리를 사용하면 당장 실행에 필요한 부분만 실제 메모리에 올려 실행하게 된다.

### 가상 메모리의 장점?
+ 프로그램이 전체 다 올라가지 않기 때문에 더 많은 프로그램들을 동시에 메모리에 올려 작업할 수 있다.
+ 한 번에 올리는 크기가 작기 때문에 Disk와 Memory간 I/O 작업 속도가 빨라진다.

### 구현 방법
1. 요구 페이징 방식
2. 요구 세그먼테이션 기법

** 메모리에서 단순 페이징, 세그먼테이션과 요구 페이징, 세그먼테이션의 다른점은 단순 페이징, 세그먼테이션은 프로세스의 페이지를 모두 적재시키지만, 요구 ~는 프로세스 페이지를 모두 적재 시킬 필요가 없다.

## 요구 페이징
요구 페이징이란 페이지를 Backing Store 에 저장했다가 필요할 때 메인 메모리로 불러와서 사용하는 것. 그 페이지가 메모리에 적재되어 있는지 아닌지는 **valid 비트 필드**의 0(없을 때) 또는 1(있을 때) 값을 통해 구분할 수 있다.

- 특징
    - 메모리 낭비를 줄임(Less I/O Needed)
    - 메모리 공간 낭비를 줄임(Less Memory Needed)
    - 빠른 응답(Faster Response)
    - 더 많은 사용자 지원(More Users)
- CPU 가 페이지를 필요로 할 때 페이지가 메모리에 없는 경우를 **페이지 결함(Page Fault)** 이라 하고 이런 경우 CPU 는 하던 일을 잠시 멈추고 필요한 페이지를 Backing Store로부터 가져온다.
- 요구 페이징에는 필요 할 때마다 메모리에 적재시키는 pure demand paging 기법과 우선 필요할 것 같은 페이지를 적재시킨 뒤에 상황에 따라 로드하는 prepaging 기법이 존재한다.
- pure 는 메모리적인 측면에서 , prepaging 은 속도 면에서 우위를 가진다.
- 장점 : 프로세스는 실행 코드 전체가 적재(Load)되기를 기다릴 필요 없이 즉시 시작될 수 있음

### Page Fault 란?
Page fault란 지금 실행시켜야 할 Page가 실제 메모리에 올라와 있지 않는 것을 말한다. Page Fault 로 인한 I/O 작업은 CPU 의 효율성을 낮추게 된다.
![image](https://user-images.githubusercontent.com/33089715/117933647-bc178600-b33c-11eb-9c8a-eaa14190fa17.png)

**Page Fault 발생하면?**

+ CPU는 운영체제에게 알리고 운영체제는 잠시 동안 CPU 작업을 멈춘다. 그리고 Disk에서 해당 부분을 찾아 실제 메모리의 비어있는 Frame에 올리고 Page Table의 해당 부분의 Bit를 Valid로 갱신한다. 트랩(Trap)에 의해 중단되었던 명령어를 다시 재개한다.

**비어있는 Frame이 존재하지 않으면?**

+ **Page Replacement 알고리즘**(이후 설명)

**페이지 적중률을 극대화 시키기 위한 방법?**

+ 지역성을 사용한다.

+ 지역성의 원리(Locality of reference) 로 인해 사실 페이지 부재 확률은 매우 낮다.

1. 시간적 지역성 : CPU는 어느 메모리 공간을 읽은 후, 시간이 지나도 그 공간을 다시 읽을 확률이 매우 높다.

    ex) 반복문 : 하나의 코드 공간을 여러 번 읽는다.

2. 공간적 지역성 : CPU가 메모리 공간을 읽을 때는 인접한 범위 내에서 읽는다는 의미

    프로그램은 대부분 절차적인 순서로 구현되어 있어 순서대로 읽는 경우가 빈번하다.

### Pure Demanding Paging vs PrePaging

1. Pure Demanding Paging

    프로세스가 최초로 실행될 때는 어떤 페이지가 알 수 없으므로, 아무 페이지도 올리지 않는다. 그러므로 프로그램을 실행하자마자 page fault가 발생한다. 즉, 순수하게 필요한 페이지만 올리는 것을 말한다.

    장점 : 메모리를 최대한 효율적으로 사용할 수 있다.

    단점 : 시작부터 page fault가 발생하므로 속도면에서 느리다.

2. Prepaging

    프로그램을 실행할 때 필요할 것이라 판단되는 페이지를 미리 올린다. 

    장점 : page fault 가 발생할 확률이 적으므로 속도면에서 빠르다.

    단점 : 미리 올라간 페이지를 사용하지 않는다면 메모리가 낭비

### Swapping vs Demanding paging

공통점 : 둘 다 메모리와 backing store(디스크)사이를 서로 오고 가는 기능을 수행

Swapping : 프로세스 단위

Demanding paging : 페이지 단위

## 페이지 교체(Page Replacement) 
Demanding Paging 은 요구 되어지는 페이지만 backing store에서 가져온다. memory full인 경우에 다른 프로그램이 새로 실행되거나 실행중인 프로세스가 다른 페이지를 요구하는 경우 이미 메모리에 있는 페이지 중 하나를 다시 backing store에 보내고(page-out) 새로운 페이지를 메모리에 올려야 한다.(page-in) 이를 페이지 교체라 한다. 여기서 backing store로 page-out 된 페이지를 victim page라고 한다.

### Victim Page
+ modified bit(dirty bit)를 추가한다.
    + 페이지의 수정여부를 판단하는 비트, 수정된 경우 1, 그렇지 않으면 0이다.
    + 희생양 페이지를 결정하는 방법 중 간단한 하나는 CPU에 수정(modify)되지 않는 페이지를 고르는 것이 효율적이다. 수정되지 않은 페이지는 page-out 이 될 때 backing store에 쓰기(write) 연산을 할 필요가 없어 Page-out 될 필요가 없고 자리에 덮어 씌우면 된다.

        ![4](https://user-images.githubusercontent.com/33089715/117935407-a73bf200-b33e-11eb-9af5-1202a227aeb8.png)

+ Page Replacement Algorithm을 사용한다.

## Page Replacement Algorithm
### 1. First In First Out(FIFO)
가장 먼저 page-in 한 페이지를 가장 먼저 page-out 시키는 알고리즘

+ 이전에 page-out한 페이지를 그 다음 바로 page-in을 하려한다면 다시 page fault가 발생하기 때문에 비효율적일 수 있다.
+ Belady's Anomaly이 있을 수 있다.

**Belady's Anomaly**

![image](https://user-images.githubusercontent.com/33089715/117953750-4b2e9900-b351-11eb-96b3-13ce5fd38622.png)

프레임 수가 증가하면(= 메모리 용량이 증가하면) page fault 수가 줄어드는 것이 정상적이지만, 특정한 페이지 참조열에 대해서는 프레임 수가 증가해도 page fault 수가 오히려 증가하는 이상 현상

### 2. Optimal(OPT)
OPT는 말그대로 가장 효율적인 페이지 교체 알고리즘이다. 이 알고리즘은 가장 오랫동안 사용되지 않을 페이지를 희생양 페이지로 선택한다.

+ 미래를 예상해야하기 때문에 현실적으로 불가능하다.

### 3. Least-Recently-Used(LRU)

최근에 사용되지 않으면 나중에도 사용되지 않을 것이라는 개념으로 과거의 페이지 기록을 통해 희생양 페이지를 선태한다.

+ LRU는 OPT보다는 page fault가 많이 발생하지만, FIFO보다는 일반적으로 적게 일어난다. 그러므로 현재 대부분 환경에서는 LRU를 사용하고 있다.

### 4. LRU Approximation 알고리즘

**1. 참조 비트(Reference Bit)**

- 모든 참조 비트는 OS 에 의해 0 으로 채워짐
- 프로세스가 실행되면서 페이지가 참조될 때마다 하드웨어가 그 페이지에 대한 참조 비트를 1로 셋
- 시간이 지나면, 페이지 사용 순서는 모르지만, 어떤 페이지가 사용 되었었는지, 한번도 사용안된 페이지가 뭔지 알 수 있음

**2. Additional-Reference-Bits**

- 페이지 당 8비트 참조 비트 존재
- 일정 시간의 간격마다 Access 되었던 페이지들의 비트를 오른쪽으로 shift 하는 연산
- 가장 큰 값의 비트를 가진 페이지가 최근에 access된 것임
- 가장 작은 값의 비트를 가진 페이지를 victim page 로 선택
- fifo 알고리즘을 이용하여 victim page 선택

    ex) 

    0-10000000

    1-10000000

    2-10000000

    <0-Page Access>

    <1-Page Access>

    ----Interrupt----

    0-01000000

    1-01000000

    2-10000000

    <2-Page Access>

    ----Interrupt----

    0-00100000

    1-00100000

    2-01000000 (가장 큰 값이므로 가장 최근에 Access)

3. Second change algorithm
- 각 page에는 1 reference bit가 0으로 초기화 되어 있다.
- 참조 비트가 0인 페이지 선택 (access 시 1로 바꿈)
- 참조 비트가 1이면 0으로 변경하고 access time 을 현재 시간으로 reset (1이라는 말은 최근에 access 되었다는 것을 의미하기 때문에 한 번의 기회를 더 준다.)

4. Enhanced Second-Change 알고리즘
- reference bit 만 보는 것이 아니라 modify bit 도 고려한다.
- (0,0) : old and not modified( BEST )

    (0,1) : old, but modified

    (1,0) : recent, but clean

    (1,1) : recent and modified

- Page Table을 전부 확인해야 한다는 단점이 있다.

### 5. Counting-Based 알고리즘
Access된 횟수를 Page table의 각 Page에 저장을 하여 횟수를 통해 Victim 페이지를 결정하는 알고리즘이다.

**1. LFU (Least Frequently Used) 알고리즘**
- 가장 작은 count 횟수인 페이지를 replace 대상으로 선택
- 왜? Active page 는 large reference count 를 가진다는 논리 (Access 횟수가 적다는 것은 "앞으로도 선택이 안될 것이다"라고 판단)

**2. MFU(Most Frequently Used) 알고리즘**

- 참조 회수가 가장 많은 페이지를 교체하는 방법
- 왜? 가장 작은 참조 회수를 가진 페이지가 가장 최근에 참조된 것이고 앞으로도 사용될 것이라는 논리("지금까지 많이 Access 참조했으니 앞으로는 Access 참조되지 않을 것이다"라고 판단)

---
### 출처

https://github.com/SSAFY-CS-STUDY/Tech_interview/tree/main/03.Operating_system

https://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-15.-%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AC

https://baked-corn.tistory.com/20?category=718232
