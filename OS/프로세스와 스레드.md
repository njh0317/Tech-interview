# 프로세스와 스레드

## 프로세스(Process)
메인 메모리에 할당되어 **실행중인 상태**인 프로그램을 말한다.
- 메모리에 올라와 실행되고 있는 프로그램의 인스턴스(Instance : 독립적인 개체)
- 운영체제로 부터 **시스템 자원을 할당 받는 작업의 단위**
- 동적인 개념으로는 실행된 프로그램을 의미

**할당 받는 시스템 자원의 예**
+ 운영되기 위해 필요한 주소 공간
+ CPU 시간
+ Code, Data, Heap, Stack 의 구조로 되어 있는 독립된 메모리 영역

### 프로세스(Process) vs 프로그램(Program)
> 프로그램이란? 파일 시스템에 존재하는 실행 파일이 프로그램이다. 보조기억장치에 존재하며 실행되기 기다리는 명령어와 정적인 데이터의 묶음

프로그램과 프로세스의 가장 큰 차이점은 프로그램은 지정된 작업을 수행하는 명령 그룹이며 프로세스는 실행중인 프로그램이라는 점이다. 여러 프로세스가 동일한 프로그램의 일부가 될 수 있다.

### 프로세스 상태
![image](https://user-images.githubusercontent.com/33089715/117449210-aa1f9700-af7a-11eb-866a-6dc44968eda7.png)

+ **New** : 프로그램이 메인 메모리에 할당된다.
+ **Ready** : 할당된 프로그램이 초기화와 같은 작업을 통해 실행되기 위한 모든 준비를 마친다.
+ **Running** : CPU가 해당 프로세스를 실행한다.
+ **Waiting** : 프로세스가 끝나지 않은 시점에서 I/O로 인해 CPU를 사용하지 않고 다른 작업을 한다. (해당 작업이 끝나면 다시 CPU에 의해 실행되기 위해 ready 상태로 돌아가야 한다.)
+ **Terminated** : 프로세스가 완전히 종료된다.

### 프로세스의 상태 전이

- **승인 (Admitted)** : 프로세스 생성이 가능하여 승인됨.
- **스케줄러 디스패치 (Scheduler Dispatch)** : 준비 상태에 있는 프로세스 중 하나를 선택하여 실행시키는 것.
- **인터럽트 (Interrupt)** : 예외, 입출력, 이벤트 등이 발생하여 현재 실행 중인 프로세스를 준비 상태로 바꾸고, 해당 작업을 먼저 처리하는 것.
- **입출력 또는 이벤트 대기 (I/O or Event wait)** : 실행 중인 프로세스가 입출력이나 이벤트를 처리해야 하는 경우, 입출력/이벤트가 모두 끝날 때까지 대기 상태로 만드는 것.
- **입출력 또는 이벤트 완료 (I/O or Event Completion)** : 입출력/이벤트가 끝난 프로세스를 준비 상태로 전환하여 스케줄러에 의해 선택될 수 있도록 만드는 것.
** running에서 ready로 변할 때는 time sharing system 에서 해당 프로세스가 CPU 시간을 모두 소진되었을 때 인터럽트에 의해 강제로 ready 상태로 변하고, CPU는 다른 프로세스를 실행시킨다.

### 특징
- 프로세스는 각각 독립된 메모리 영역(Code, Data, Stack, Heap 등)을 할당 받음
- 기본적으로 프로세스 당 최소 1개의 스레드(메인 스레드)를 가지고 있음
- 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없음
- 다른 프로세스에 접근하기 위해서는 프로세스 간 통신(IPC : Inter-Process Communication)을 사용해야 함

### 프로세스 메모리 구조

- Stack : 프로그램이 자동으로 사용하는 임시 메모리 영역으로 지역변수, 매개변수, 리턴 값 등이 잠시 사용 되었다가 사라지는 데이터를 저장하는 영역이다. 함수 호출 시 생성되고 함수가 끝나면 반환된다.
- Heap : 필요에 의해 메모리를 동적 할당하고자 할 때 사용하는 메모리 영역으로 동적 데이터 영역이라고 부른다. 메모리 주소 값에 의해서만 참조되고 사용하는 영역이다. 이 영역에 데이터를 저장하기 위해 C 에서는 malloc() 함수를 사용한다.
- Data : 프로그램이 실행될 때 생성되고 프로그램이 종료되면 시스템에 반환 되며 전역 변수, 정적 변수, 배열, 구조체 등이 저장된다.

    - 함수 내부에 선언된 Static 변수는 프로그램이 실행될 때 공간만 할당되고 그 함수가 실행될 때 초기화된다.
    - 초기화 된 데이터는 Data 영역에 저장되고 초기화되지 않은 데이터는 BSS(Block Stated Symbol) 영역에 저장된다. 
        - 이유? : 프로그램을 짠 뒤 컴파일하고 링크하고 이미지로 만들어 시스템의 ROM에 저장했다고 가정해보자. 이 때 초기화된 데이터는 초기 값을 저장해야하므로 Data 영역에 저장되어 ROM에 저장된다. 하지만 초기화하지 않은 데이터까지 ROM에 저장한다면 큰 사이즈의 ROM 이 필요한데 비용이 많이 들어 RAM 에 저장하기 위해 Data 영역과 BSS 영역으로 나누었다.
- Code : 코드 자체를 구성하는 메모리 영역으로 Hex 파일이나 Bin 파일 메모리이다. 

### PCB(Process Control Block, 프로세스 제어 블록)란?
프로세스에 대한 모든 정보가 모여있는 곳이다.
+ 운영체제 내부의 프로세스를 관리하는 코드 부분에 저장되어 있다.
+ **PCB에 저장되는 정보**
    - 프로세스 식별자(Process ID, PID) : 프로세스 식별 번호
    - 프로세스 상태 : (new, ready, running, waiting, terminated) 등의 상태를 저장
    - 프로그램 카운터 (PC) : 프로세스가 다음에 실행할 명령어 주소
    - CPU 레지스터
    - CPU 스케줄링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터
    - 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
    - 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
- 프로세스의 생성과 동시에 고유한 PCB를 생성
- **프로세스는 CPU를 할당 받아 작업을 처리하다가 Context Switching 이 발생하면 진행하던 작업을 저장하고 CPU에 반환 해야 하는데, 이때 진행 상황을 모두 PCB 에 저장**

### 프로세스 큐(Queue)란?
프로세스는 일반적으로 여러 개가 한 번에 수행되므로 그에 따른 순서가 필요하다. 이러한 순서를 대기하는 곳을 큐(Queue)라고 부른다.
![image](https://user-images.githubusercontent.com/33089715/117451352-65492f80-af7d-11eb-867c-06bcaa11417f.png)
+ Job Queue : 하드디스크에 있는 프로그램이 실행되기 위해 메인 메모리의 할당 순서를 기다리는 큐
    + Job Scheduler(Long-term scheduler) : 스케줄링이 발생하는 시간이 비교적 오래 걸림
+ Ready Queue : CPU 점유 순서를 기다리는 큐
    + CPU Scheduler(Short-term scheduler) : 스케줄링이 발생하는 시간이 비교적 짧게 걸림
+ Device Queue : I/O를 하기 위한 여러 장치가 있는데, 각 장치를 기다리는 큐가 각각 존재한다.
    + Device Scheduler

> 각 큐 내부에 저장된 실제 데이터는 각 프로세스의 PCB가 저장되어 있다. 

> 순서를 기다리는 공간이 있다면 이 순서를 저장해주는 알고리즘이 있다. 이러한 알고리즘을 스케줄링(Scheduling)이라 한다.

### 멀티 프로그래밍(Multiprogramming)
단일 프로세서(CPU) 환경에서 **여러 개의 프로세스가 동시에 실행**되는 것처럼 보이는 것을 말한다.

**I/O Bound process VS CPU Bound process**
- I/O bound process: 해당 프로세스에서 I/O(입출력) 작업이 차지는 비중이 높은 프로세스를 말한다.
- CPU bound process: 해당 프로세스에서 CPU 작업(계산)이 차지는 비중이 높은 프로세스를 말한다.
- 운영체제, 정확히 말하면 job scheduler 는 I/O bound process와 CPU bound process를 적절히 분배해서 메모리에 할당해주어야 한다.

**Medium-term scheduler**

운영체제가 실행하는 동안 주기적으로 메인 메모리에 있는 전체 프로세스를 검사하여 보조기억장치로 옮길 프로세스를 찾아 옮기는 스케줄러이다.
+ **Swapping** : 메인 메모리에서 장시간 사용하지 않는 프로세스를 하드디스크(Swap device = Backing store)로 옮겨주고(Swap out), 나중에 이 프로세스가 다시 사용되려고 하면 하드디스크에서 해당 프로세스를 다시 메인 메모리에 할당해준다.(Swap in)
> 일반적으로 하드디스크는 File system + Backing store로 구성되어 있다.

**Context Switching(문맥 전환)**

Context switching은 CPU가 한 프로세스에서 다른 프로세스로 옮겨가는 것을 말한다. 즉, 한 프로세스가 실행중인 것을 멈추고 다른 프로세스가 실행되는 것이다.

- Scheduler: 여기서 스케줄러는 CPU Scheduler를 말하며, CPU가 어느 프로세스를 선택할지 정한다.
- Dispatcher: 실제 context switching이 발생하면 CPU의 내부 데이터를 이전 프로세스 데이터에서 새로 시작되는 데이터로 바꿔준다. 다시 말해서 현재 CPU 데이터는 이전 프로세스의 PCB에 갱신하고, 새로 시작되는 프로세스의 PCB 데이터를 CPU로 복원(restore) 해준다.
- Context switching overhead: Context switching이 발생할 때마다, dispatcher에서 수행하는 작업을 매번 수행해야하며 이 모든 것은 overhead이다. 그리고 문맥 전환은 매우 자주 발생하는 작업이므로 overhead를 줄이기 위해서는 dispatcher를 구현하는 코드에 대한 효율을 최대한 높여주어야한다.

> 보통 인터럽트가 발생하거나(`Ready → Running`), 실행중인 CPU 사용 허가 시간을 모두 소모하거나(`Running → Ready`), 입출력을 위해 대기해야 하는 경우(`Running → Waiting`) 에 Context Switching 발생

> 참고로 Context Switching 때 해당 CPU는 아무런 일을 하지 못한다. 따라서 컨텍스트 스위칭이 잦아지면 오히려 오버헤드가 발생해 효율(성능)이 떨어진다.

### IPC(Interprocess Communication)

프로세스 간 통신

각 프로세스는 독립적이기 때문에 데이터를 주고받기 위해서는 IPC 를 사용한다.

1. **공유메모리(Shared Memory)** 

    **특징**

    - 두 개 이상의 프로세스들이 주소 공간의 일부를 공유, 공유한 메모리 영역에 읽기/쓰기를 통해 통신 수행(Read and Write)
    - 공유 메모리가 설정되면, 그 이후 통신은 커널 관여 없이 진행 가능
    - update 가 즉시 모든 프로세스에게 보인다.
    - single system 에서 사용

    **장점**

    - 커널의 관여가 없이 메모리를 직접 사용해 IPC 속도가 빠르다.
    - 프로그램 레벨에서 통신 기능을 제공하여, 자유로운 통신이 가능

    **단점**

    - 구현이 어렵다

    **Context Switching 관점**

    - 공유 메모리 모델에서의 IPC 는 해당 프로세스가 CPU 를 사용하는 행위이다.
    - 즉, IPC 를 많이 한다고 컨텍스트 스위칭이 많이 일어나지 않는다.

    **동기화 관점**

    - 메모리 영역에 대한 동시적인 접근을 제어하기 위한 방법이 필요하다.
    - 커널이 동기화를 제공하지 않으며, 부가적인 방법이 필요하다.
    - locking 혹은 세마포어

    공유 메모리 모델의 활용의 예 : 데이터베이스

    공유 메모리 모델의 구현 IPC : 공유 메모리(Shared Memory) 

2. **메시지 전달(Message Passing)**

    **특징**

    - 커널 경유하여 고정 길이 메시지, 가변 길이 메시지를 송/수신자 끼리 주고 받으며 커널 에서는 데이터를 버퍼링(Send and Receive)
    - 프로세스 간 메모리 공유 없이 동작이 가능

    **장점**

    - 구현 간단, 사용 편리

    **단점**

    - 커널 경유하므로 속도 느림

    **Context Switching 관점**

    - 메시지 전달 모델에서의 IPC 는 해당 프로세스 입장에서 일종의 입출력(I/O) 로 볼 수 있다.
    - 즉 IPC를 하면 할수록 컨텍스트 스위칭이 많이 일어난다.
    - 예를 들어 send 하고 상대방이 받을 때까지 기다려야 하며, 이 때 컨텍스트 스위칭이 발생한다. 마찬가지로 receive 하면 상대방이 보낼 때까지 기다려야 하며, 이 때 컨텍스트 스위칭이 발생한다.

    **동기화 관점**

    - send 와 receive 같은 연산에 대해서는 커널이 동기화를 제공한다.
    - send 와 receive 를 수행할 때에 프로그램은 동기화에 대한 고려 없이 사용할 수 있다.

    메시지 전달 모델 활용의 예 : 서버-클라이언트 방식의 통신

    메시지 전달 모델의 구현 IPC : PIPE, Message Queue, Socket, Signal,...

    **1) 파이프(Pipe)**

    특징

    - 하나의 프로세스가 다른 프로세스로 데이터를 직접 전달
    - 데이터는 한 쪽 방향으로만 이동한다. 따라서 양 방향 통신을 하기 위해서는 두 개의 파이프가 필요
    - 1:1 통신만 가능하다.
    - 보내진 순서대로만 받는다.(in-order)
    - 용량 제한이 있기 때문에 파이프가 가득 차면 더이상 쓸 수 없다.



    **2) 시그널(Signal)**

    특징

    - pid 를 아는 특정 프로세스에게 커널을 통해 이벤트를 전달하는 방법 → 이 때 어떤 이벤트 인지 시그널 번호로 알 수 있다.
    - 송신 측 프로세스가 시그널을 보내는 동작은 수신 측 프로세스의 상태에 무관하게 수행 → 수신 측 프로세스에서 시그널을 처리하는 것은 수신 측 프로세스가 스케줄링 되어야 가능하다. 즉 비동기적
    - 수신 측 프로세스는 시그널 종류에 따라 시그널 처리 방법을 지정


    **3) 메시지 큐(Message Queue)**

    특징

    - 고정된 크기를 갖는 메시지의 연결 리스트를 이용하여 통신을 하는 방법
    - 메시지 단위의 통신이다.
    - 메시지 형태는 사용자가 정의 가능, 통신하고자 하는 프로세스 간의 약속이 필요하다.
    - 메시지 큐에는 여러 프로세스가 동시에 접근이 가능하며, 동기화가 필요하다.


    **4) 소켓(Socket)**

    특징

    - An Endpoint for Communication
    - 운영체제가 제공하는 포트(Port)라는 Abstraction을, 여러 프로세스가 사용할 수 있도록 해 준다.
    - 프로세스는 포트 번호를 이용하여 통신하려는 상대 프로세스의 소켓을 찾아간다.
    - 포트의 도움으로, 다른 IPC와 달리 프로세스의 "위치"에 독립적이며, machine boundary 와 관계가 없다. (Local 뿐 아니라 Remote 에서도 사용 가능, 다른 IPC 는 Local 에서만 사용할 수 있다.)


## 스레드(Thread)
프로세스 내에서 실행되는 여러 흐름의 단위

- 프로세스의 특정한 수행 경로
- 프로세스가 할당 받은 자원을 이용하는 실행의 단위
- 스레드 ID, 프로그램 카운터(PC), 레지스터 집합, 스택으로 구성

### 특징
- 스레드는 프로세스 내에서 각각 Stack 영역과 PC 레지스터를 독립적으로 따로 할당받고 Code, Data, Heap 영역은 공유한다.
    - **Stack 영역을 독립적으로 할당 받는 이유?**

        함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언된 변수 등을 저장하기 위해 독립적인 공간이 필요하다.

        + 즉, 독자적인 실행 흐름을 저장하기 위해 Stack 영역을 독립적으로 할당받는다.

    - **PC 레지스터를 독립적으로 할당 받는 이유?**

        현재 스레드의 명령어 진행 수행이 어디까지 되었는지에 대한 정보가 필요하며, 해당 정보는 PC 에 저장된다.

        CPU 할당 시 스케줄러는 스레드의 PC 레지스터 정보 값을 기준으로 다시 수행한다.

- 스레드는 한 프로세스 내에서 동작하는 여러 실행의 흐름으로, 프로세스 내에서 주소 공간이나 자원(힙 공간)을 같은 프로세스 내에서 스레드 끼리 공유하며 실행된다.
- 각 스레드는 별도의 레지스터와 스택을 갖고 있지만, 힙 메모리는 공유한다.
- 한 스레드가 프로세스 자원을 변경하면 다른 이웃 스레드도 그 변경 결과를 즉시 볼 수 있다.

### 다중 스레드(Multithread)란?
프로그램에 여러 개의 쓰레드 즉, 흐름이 있을 수 있는 이유는 쓰레드가 빠른 시간 간격으로 스위칭되기 때문이다. 이러한 동작으로 사용자는 여러 쓰레드가 동시에 실행되는 것처럼 보인다. 이것을 다중 스레드라 한다.

+ 예를들어 Web Browser가 있다. 화면을 출력하는 스레드와 데이터를 읽어오는 스레드가 기본적으로 따로 수행된다. 
> 이처럼 CPU가 하나인 환경에서 여러 쓰레드가 스위칭에 의해 동시에 수행되는 효과를 concurrent라 한다. 반면에 여러 CPU 환경에서 여러 쓰레드가 실제로 동시에 수행되는 것은 simultaneous라고 한다.

### Thread-safe 란?
멀티 스레드 환경에서 여러 스레드가 동시에 하나의 객체 및 변수에 접근할 때, 의도한 대로 동작하는 것을 말한다.

- Thread-safe 하게 구현한다 라는 것은?
    - 공유 자원에 접근하는 임계영역(Critical Section)을 동기화 기법으로 제어해야 한다 →  상호 배제
    - Mutex, Semaphore 를 활용한다.


## 멀티 프로세스 vs 멀티 스레드
**멀티 프로세스 대신 멀티 스레드를 사용하는 이유?**
### 멀티 프로세스
+ 장점 : 안정성이 높다.(메모리를 프로세스 별로 할당받기 때문에 독립된 구조를 가진다.)
+ 단점 : 각각 독립된 메모리 영역을 갖고 있어, 작업량이 많을 수록 overhead 가 발생한다. Context Switching으로 인한 성능 저하가 일어날 수 있다.

### 멀티 스레드
+ 단점 : 여러 개의 스레드를 이용하는 경우, 미묘한 시간 차나 변수를 공유 함으로서 오류가 발생할 수 있다.(**동기화 문제**를 해결해야 한다.) 단일 프로세스 시스템에서는 효과를 기대하기 어렵다.

+ 장점 : 여러개의 프로그램을 실행시키는 것 보다, 하나의 프로그램 안에서 여러 작업을 수행하는 것이 효율적이다.
1. 자원의 효율성 증다
- 멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우, 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있음
    - 프로세스 간의 Context switching 시 단순히 CPU 레지스터 교체 뿐만 아니라 RAM 과 CPU 사이의 캐시 메모리에 대한 데이터 까지 초기화 되므로 오버헤드가 크기 때문
- 스레드는 프로세스 내의 메모리를 공유하기 때문에 독립적인 프로세스와 달리 스레드 간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모가 줄어들게 됨
    - 스레드는 Stack 이외의 모든 메모리를 공유하므로 Context Switching 시 Stack 영역만 바꾸면 되기 때문에 비용이 적게듬

2. 처리 비용 감소 및 응답 시간 단축
- 프로세스 간 통신(IPC) 보다 스레드 간의 통신의 비용이 적으므로 작업들 간의 통신 부담이 줄어듬
    - 스레드는 Stack 영역을 제외한 모든 메모리를 공유하기 때문
- 프로세스 간 전환 속도보다 스레드 간의 전환 속도가 빠름
    - context switching 시 스레드는 Stack 영역만 처리하기 때문(나머지는 공유 중이니까!)


### 멀티 스레드의 효율성과 안정성 문제
여러 개의 스레드가 동일한 데이터 공간을 공유하면서 이들을 수정하기 때문에 발생하는 문제이다.

멀티 프로세스 방식의 프로그램에서 하나의 프로세스가 자신의 데이터 공간을 망가뜨린다면, 그 것은 해당 프로세스의 중단을 낳게 될 것이다. 하지만 멀티 스레드 방식의 프로그램에서는 하나의 스레드가 자신이 사용하던 데이터 공간을 망가뜨린다면 그 결과는 하나의 데이터 공간을 공유하는 모든 스레드를 작동불능 상태로 만든다.

이러한 문제에 대비해 **Critical Section** 기법이 존재한다.
