# 캐시
속도가 빠른 저장 장치와 느린 저장 장치 사이에 속도 차이에 따른 병목현상을 줄이기 위한 범용 메모리이다. 지역성을 이용해 CPU가 어떤 데이터를 원할 것인가를 어느 정도 예측해 캐시 메모리에 데이터를 저장한다.

- 주기억장치와 CPU 사이에 위치
- 캐시는 CPU 칩 안에 들어가는 작고 빠른 메모리다. (그리고 비싸다.) 
- 프로세서가 매번 메인 메모리에 접근해 데이터를 받아오면 시간이 오래 걸리기 때문에 캐시에 자주 사용하는 데이터를 담아두고, 해당 데이터가 필요할 때 프로세서가 메인 메모리 대신 캐시에 접근하도록해 처리 속도를 높인다.

## 지역성(Locality)의 원리?
캐시는 `적중율(Hit rate)`을 극대화 시키기 위해 데이터 `지역성(Locality)의 원리`를 사용한다. 지역성의 전제조건으로 프로그램은 모든 코드나 데이터를 균등하게 Access 하지 않는다는 특성을 기본으로 한다. 즉, `Locality`란 기억 장치 내의 정보를 균일하게 Access 하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성인 것이다.

지역성은 대표적으로 시간 지역성(Temporal Locality)과 공간 지역성(Spatial Locality)으로 나뉜다.

- 시간 지역성 : 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성.
- 공간 지역성 : 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성
 
## 캐시 구조
```
+-------------+------+------+     +---------------+     +--------+
|             |  I$  |      | <-- |               | <-- |        |
+  Processor  +------+  L2  |     |  Main Memory  |     |  Disk  |
|             |  D$  |      | --> |               | --> |        |
+-------------+------+------+     +---------------+     +--------+
```

+ L1 Cache: 프로세서와 가장 가까운 캐시. 속도를 위해 I$와 D$로 나뉜다.
    + Instruction Cache (I$): 메모리의 TEXT 영역 데이터를 다루는 캐시.
    + Data Cache (D$): TEXT 영역을 제외한 모든 데이터를 다루는 캐시.
+ L2 Cache: 용량이 큰 캐시. 크기를 위해 L1 캐시처럼 나누지 않는다.
+ L3 Cache: 멀티 코어 시스템에서 여러 코어가 공유하는 캐시.


## LRU Cache
LRU는 OS의 페이지 교체 알고리즘의 하나로 최근에 가장 오랫동안 사용하지 않은 페이지를 교체하는 기법이다. 캐시에 공간이 부족하면 가장 최근에 사용하지 않은 항목을 지거한다.

### LRU Cache 구현
+ Doubly Linked List를 통해 구현한다.
+ head에 가까운 데이터일수록 최근에 사용한 데이터이고, tail에 가까울 수록 가장 오랫동안 사용하지 않은 데이터로 간주하여 새로운 데이터를 삽입할 때 가장 먼저 삭제되도록 한다.
+ 삽입된 데이터를 사용하게 되면 head로 옮겨 우선순위를 높이게 되고, 삭제될 우선순위에서 멀어지게 된다.
---
### 출처


